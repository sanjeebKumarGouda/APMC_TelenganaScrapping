{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date and Market added FINAL and data scraping is done for N days\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import datetime\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "    \n",
    "f = int(input('Enter upto How many days You want to scrap data from Today: '))\n",
    "dt_lst = []\n",
    "today = datetime.date.today()\n",
    "for d in range(2,f):\n",
    "    start_date = today - datetime.timedelta(d)\n",
    "    start_date_string = str(start_date.strftime(\"%d-%m-%Y\"))\n",
    "    dt_lst.append(start_date_string)\n",
    "\n",
    "\n",
    "#p_1 = []\n",
    "#for n in range(0,100):\n",
    "#    p_1.append('//*[@id=\"ContentPlaceHolder1_DataList1_Button1_' + str(n) +'\"]')\n",
    "\n",
    "p_2 = []\n",
    "for m in range(0,5):\n",
    "    p_2.append('//*[@id=\"ContentPlaceHolder1_grdDaily\"]/tbody/tr[' + str(m) +']/td[2]/a')\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df_list = []\n",
    "try:\n",
    "    for dt in range(len(dt_lst)):\n",
    "        print(dt_lst[dt])\n",
    "        date_td = dt_lst[dt]\n",
    "        p_1 = []\n",
    "        for n in range(0, 100):\n",
    "            p_1.append('//*[@id=\"ContentPlaceHolder1_DataList1_Button1_' + str(n) + '\"]')\n",
    "        for w in range(0,110):\n",
    "            print(f'w value after: {w}')\n",
    "            try:\n",
    "                PATH = \"C:\\Program Files (x86)\\chromedriver.exe\"\n",
    "                options = Options()\n",
    "                options.add_argument(\"--headless\")\n",
    "                driver = webdriver.Chrome(chrome_options=options, executable_path=PATH)\n",
    "                driver.get('http://tsmarketing.in/HomePageGe.aspx')\n",
    "\n",
    "\n",
    "                dateclick = driver.find_element_by_xpath('//*[@id=\"ContentPlaceHolder1_txtDate\"]')\n",
    "                dateclick.click()\n",
    "                dateclick.send_keys(Keys.CONTROL, 'a')\n",
    "                #dateclick.send_keys(Keys.BACK_SPACE)\n",
    "                dateclick.send_keys(dt_lst[dt])\n",
    "                dateclick.send_keys(Keys.RETURN)\n",
    "\n",
    "                for p1 in p_1:\n",
    "                    search = driver.find_element_by_xpath(p1)\n",
    "                    print(search.text)\n",
    "                    p_1.remove(p1)\n",
    "                    search.send_keys(Keys.RETURN)\n",
    "                    for p2 in p_2:\n",
    "                        try:\n",
    "                            link_text = WebDriverWait(driver, 2).until(EC.presence_of_element_located((By.XPATH, p2)))\n",
    "                            print(link_text.text)\n",
    "                            mar = link_text.text\n",
    "                            link_text.send_keys(Keys.RETURN)\n",
    "\n",
    "                            soup_level3 = BeautifulSoup(driver.page_source, 'lxml')\n",
    "                            table = soup_level3.find(\"table\",{\"id\":\"ContentPlaceHolder1_grdDaily\"})\n",
    "                            table_rows = table.find_all('tr')\n",
    "\n",
    "                            test_list = []\n",
    "                            for tr in table_rows:\n",
    "                                td = tr.find_all('td')\n",
    "                                row = [tr.text for tr in td]\n",
    "                                test_list.append(row)\n",
    "\n",
    "                            column_list = []\n",
    "                            for tr in table_rows:\n",
    "                                th = tr.find_all('th')\n",
    "                                col = [tr.text for tr in th]\n",
    "                                column_list.append(col)\n",
    "\n",
    "\n",
    "                            test_df = pd.DataFrame(test_list)\n",
    "                            test_df.columns = column_list[0]\n",
    "                            test_df = test_df.apply(lambda line: line.str.strip().replace('\\n', ''))\n",
    "                            df = test_df\n",
    "                            df['Market_Name'] = mar\n",
    "                            df['Date'] = date_td\n",
    "                            df_list.append(df)\n",
    "                            print(len(df_list))\n",
    "                            driver.back() # back from page 3 to 2 for all three market\n",
    "\n",
    "                        except Exception as e:\n",
    "                            #print(e)\n",
    "                            driver.quit()\n",
    "\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "#print(len(df_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(df_list))\n",
    "list_f = []\n",
    "for t in range(len(df_list)):\n",
    "    temp = \"f\" + str(t)\n",
    "    list_f.append(temp)\n",
    "    \n",
    "\n",
    "final_df = df_list[0]\n",
    "for u in range(1,len(df_list)):\n",
    "    l = list_f[u]\n",
    "    l = df_list[u]\n",
    "    final_df = pd.concat([final_df,l])\n",
    "#print(final_df)\n",
    "try:\n",
    "    final_df.drop(['Market Code', 'Market'], axis=1, inplace=True)\n",
    "except:\n",
    "    pass\n",
    "final_df.dropna(inplace=True)\n",
    "final_df = final_df[final_df['Commission Agent'] != '']\n",
    "final_df.to_csv(r\"C:\\Users\\Sanjeeb\\Desktop\\Gramoday\\2webScrap\\generatedCSV\\d07_06_21_notMapped.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping Mandal and Village"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_df = pd.read_csv(r\"C:\\Users\\Sanjeeb\\Desktop\\Gramoday\\2webScrap\\generatedCSV\\d13_05_21_notMapped.csv\")\n",
    "final_df['Mandal'] = final_df['Mandal'].str.upper()\n",
    "final_df['Village'] = final_df['Village'].str.upper()\n",
    "final_df['Commodity'] = final_df['Commodity'].str.upper()\n",
    "final_df['Vehicle No'] = final_df['Vehicle No'].str.upper()\n",
    "final_df['Market_Name'] = final_df['Market_Name'].str.upper()\n",
    "#final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.columns = ['No', 'Commission_Agent', 'Farmer_Name', 'Quantity', 'Units', 'Mandal','Village', 'Vehicle', 'Vehicle_No', 'Commodity', 'Lot_Number', 'Market_Name', 'Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_district = pd.read_excel(r\"C:\\Users\\Sanjeeb\\Desktop\\Gramoday\\2webScrap\\Gramoday_Datasets_market.xlsx\", sheet_name=1, usecols=['name','loclevel3','loclevel2'])\n",
    "df_district['name'] = df_district['name'].str.upper()\n",
    "#df_district.head()\n",
    "\n",
    "dict_3_to_2 = dict(zip(df_district['loclevel3'].tolist(), df_district['loclevel2'].tolist()))\n",
    "#dict_3_to_2\n",
    "dict_3_to_district = dict(zip(df_district['loclevel3'].tolist(), df_district['name'].tolist()))\n",
    "#dict_3_to_district\n",
    "dict_district_to_3 = dict(zip(df_district['name'].tolist(), df_district['loclevel3'].tolist()))\n",
    "#dict_district_to_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dist_to_dist = pd.read_excel(r\"C:\\Users\\Sanjeeb\\Desktop\\Gramoday\\2webScrap\\Gramoday_Datasets_market.xlsx\", sheet_name=7)\n",
    "df_dist_to_dist['name1'] = df_dist_to_dist['name1'].str.upper()\n",
    "df_dist_to_dist['name2'] = df_dist_to_dist['name2'].str.upper()\n",
    "#df_dist_to_dist.head()\n",
    "\n",
    "dict_dist_to_dist = dict(zip(df_dist_to_dist['name1'].tolist(), df_dist_to_dist['name2'].tolist()))\n",
    "#print(dict_dist_to_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_state = pd.read_excel(r\"C:\\Users\\Sanjeeb\\Desktop\\Gramoday\\2webScrap\\Gramoday_Datasets_market.xlsx\", sheet_name=2)\n",
    "df_state['name'] = df_state['name'].str.upper()\n",
    "#df_state\n",
    "\n",
    "dict_id_to_state = dict(zip(df_state['ID'].tolist(), df_state['name'].tolist()))\n",
    "#print(dict_id_to_state)\n",
    "dict_id_to_shortname = dict(zip(df_state['ID'].tolist(), df_state['shortName'].tolist()))\n",
    "#print(dict_id_to_shortname)\n",
    "dict_shortname_to_state = dict(zip(df_state['shortName'].tolist(), df_state['name'].tolist()))\n",
    "#print(dict_shortname_to_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_state_to_state = pd.read_excel(r\"C:\\Users\\Sanjeeb\\Desktop\\Gramoday\\2webScrap\\Gramoday_Datasets_market.xlsx\", sheet_name=6)\n",
    "df_state_to_state['name1'] = df_state_to_state['name1'].str.upper()\n",
    "df_state_to_state['name2'] = df_state_to_state['name2'].str.upper()\n",
    "#df_state_to_state.head()\n",
    "\n",
    "dict_state_to_state = dict(zip(df_state_to_state['name1'].tolist(), df_state_to_state['name2'].tolist()))\n",
    "#print(dict_state_to_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mandal = pd.read_excel(r\"C:\\Users\\Sanjeeb\\Desktop\\Gramoday\\2webScrap\\Gramoday_Datasets_market.xlsx\", sheet_name=4, usecols=['name', 'loclevel3'])\n",
    "df_mandal['name'] = df_mandal['name'].str.upper()\n",
    "#print(df_mandal.head())\n",
    "\n",
    "dict_mandal_to_3 = dict(zip(df_mandal['name'].tolist(), df_mandal['loclevel3'].tolist()))\n",
    "#print(dict_mandal_to_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['DistrictID_M'] = final_df.Mandal.map(dict_mandal_to_3)\n",
    "final_df['DistrictM'] = final_df.DistrictID_M.map(dict_3_to_district)\n",
    "final_df['ID2_3'] = final_df.DistrictID_M.map(dict_3_to_2)\n",
    "final_df['StateM'] = final_df.ID2_3.map(dict_id_to_state)\n",
    "#final_df['State_short_nameM'] = final_df.ID2_3.map(dict_id_to_shortname)\n",
    "\n",
    "final_df.drop(['DistrictID_M', 'ID2_3'], axis=1, inplace=True)\n",
    "#final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['DistrictID_V'] = final_df.Village.map(dict_mandal_to_3)\n",
    "final_df['DistrictV'] = final_df.DistrictID_V.map(dict_3_to_district)\n",
    "final_df['ID2_3_V'] = final_df.DistrictID_V.map(dict_3_to_2)\n",
    "final_df['StateV'] = final_df.ID2_3_V.map(dict_id_to_state)\n",
    "#final_df['State_short_nameV'] = final_df.ID2_3_V.map(dict_id_to_shortname)\n",
    "\n",
    "final_df.drop(['DistrictID_V', 'ID2_3_V'], axis=1, inplace=True)\n",
    "#final_df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['State1'] = final_df.Village.map(dict_shortname_to_state)\n",
    "final_df['State2'] = final_df.Village.map(dict_state_to_state)\n",
    "final_df['District1'] = final_df.Village.map(dict_dist_to_dist)\n",
    "final_df['level3'] = final_df.District1.map(dict_district_to_3)\n",
    "final_df['level2'] = final_df.level3.map(dict_3_to_2)\n",
    "final_df['State3'] = final_df.level2.map(dict_id_to_state)\n",
    "\n",
    "final_df.drop(['level3', 'level2'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_df.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Truck Number Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_truck_no = pd.read_excel(r\"C:\\Users\\Sanjeeb\\Desktop\\Gramoday\\2webScrap\\Gramoday_Datasets_market.xlsx\", sheet_name=9, usecols=['Code', 'Jurisdiction', 'State'])\n",
    "df_truck_no['Code'] = df_truck_no['Code'].str.upper()\n",
    "#print(df_truck_no.head())\n",
    "#final_df['Vehicle No'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_truck_no['Code'] = df_truck_no['Code'].str.replace( \"[-]\", \"\")\n",
    "final_df['Vehicle_No'] = final_df['Vehicle_No'].apply(lambda x:x[0:4])\n",
    "\n",
    "#print(final_df['Vehicle No'].head())\n",
    "#print(df_truck_no['Code'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict_code_to_juri = dict(zip(df_truck_no['Code'].tolist(), df_truck_no['Jurisdiction'].tolist()))\n",
    "#print(dict_code_to_juri)\n",
    "dict_code_to_state = dict(zip(df_truck_no['Code'].tolist(), df_truck_no['State'].tolist()))\n",
    "#print(dict_code_to_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['Vehicle_Jurisdiction'] = final_df.Vehicle_No.map(dict_code_to_juri)\n",
    "final_df['Vehicle_State'] = final_df.Vehicle_No.map(dict_code_to_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping Commodity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_commodity = pd.read_excel(r\"C:\\Users\\Sanjeeb\\Desktop\\Gramoday\\2webScrap\\Gramoday_Datasets_market.xlsx\", sheet_name=8, usecols=['Commodity', 'Changes', 'Category'])\n",
    "df_commodity['Commodity'] = df_commodity['Commodity'].str.upper()\n",
    "df_commodity['Changes'] = df_commodity['Changes'].str.upper()\n",
    "df_commodity['Category'] = df_commodity['Category'].str.upper()\n",
    "#print(df_commodity.head(20))\n",
    "\n",
    "dict_commodity_to_changes = dict(zip(df_commodity['Commodity'].tolist(), df_commodity['Changes'].tolist()))\n",
    "#print(dict_commodity_to_changes)\n",
    "dict_changes_to_category = dict(zip(df_commodity['Changes'].tolist(), df_commodity['Category'].tolist()))\n",
    "#print(dict_changes_to_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['Commodity'] = final_df.Commodity.map(dict_commodity_to_changes)\n",
    "final_df['Category'] = final_df.Commodity.map(dict_changes_to_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "final_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(r\"C:\\Users\\Sanjeeb\\Desktop\\Gramoday\\2webScrap\\generatedCSV\\d07_06_21_Mapped.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Superimposing Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = final_df[['StateM', 'StateV', 'State1', 'State2', 'State3', 'DistrictM', 'DistrictV', 'District1']]\n",
    "#df = pd.read_csv(r\"C:\\Users\\Sanjeeb\\Desktop\\Gramoday\\2webScrap\\generatedCSV\\d07_06_21_Mapped.csv\", usecols=['StateM', 'StateV', 'State1', 'State2', 'State3', 'DistrictM', 'DistrictV', 'District1'])\n",
    "df.replace(to_replace=np.nan, value='', inplace=True)\n",
    "df.columns = ['DistrictA', 'StateA', 'DistrictB', 'StateB', 'StateC', 'StateD','DistrictC', 'StateE']\n",
    "#print(df.head(10))\n",
    "\n",
    "lst_index = []\n",
    "lst_state = []\n",
    "for index, row in df.iterrows():\n",
    "    lst_state.append(row['StateA'] or row['StateB'] or row['StateC'] or row['StateD'] or row['StateE'])\n",
    "    lst_index.append(index)\n",
    "#print(len(lst_state))\n",
    "df_state = pd.DataFrame()\n",
    "df_state[\"State\"] = lst_state\n",
    "df_state[\"IndexNo\"] = lst_index\n",
    "#print(df_state.head(10))\n",
    "\n",
    "lst_district = []\n",
    "for index, row in df.iterrows():\n",
    "    lst_district.append(row['DistrictA'] or row['DistrictB'] or row['DistrictC'])\n",
    "#print(len(lst_district))\n",
    "df_district = pd.DataFrame()\n",
    "df_district[\"District\"] = lst_district\n",
    "df_district[\"IndexNo\"] = lst_index\n",
    "#print(df_district.head(10))\n",
    "\n",
    "df[\"IndexNo\"] = lst_index\n",
    "final_df[\"IndexNo\"] = lst_index\n",
    "#print(df.head(10))\n",
    "\n",
    "t1 = pd.merge(df_state,df_district,on='IndexNo')\n",
    "#t2 = pd.merge(df,t1,on='IndexNo')\n",
    "final_dataframe = pd.merge(final_df,t1,on='IndexNo')\n",
    "final_dataframe.drop(['DistrictM', 'StateM', 'DistrictV', 'StateV', 'State1','State2', 'District1', 'State3', 'IndexNo'], axis=1,inplace=True)\n",
    "#final_dataframe.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataframe.to_csv(r\"C:\\Users\\Sanjeeb\\Desktop\\Gramoday\\2webScrap\\generatedCSV\\d07_06_21_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
